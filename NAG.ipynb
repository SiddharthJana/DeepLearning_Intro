{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hsm6OOWNz_LJ"
      },
      "outputs": [],
      "source": [
        "# Nesterov Accelerated Gradient Descent\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation function\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)"
      ],
      "metadata": {
        "id": "zLLej-E50Ve3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# He initialization\n",
        "def he_initialization(shape):\n",
        "    return np.random.randn(*shape) * np.sqrt(2 / shape[0])"
      ],
      "metadata": {
        "id": "OhaSCkyJ0ZMV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network Model\n",
        "class NeuralNet:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.fc1_weights = he_initialization((input_size, hidden_size))\n",
        "        self.fc1_bias = np.zeros(hidden_size)\n",
        "        self.fc2_weights = he_initialization((hidden_size, output_size))\n",
        "        self.fc2_bias = np.zeros(output_size)\n",
        "        self.v_fc1_weights = np.zeros_like(self.fc1_weights)\n",
        "        self.v_fc1_bias = np.zeros_like(self.fc1_bias)\n",
        "        self.v_fc2_weights = np.zeros_like(self.fc2_weights)\n",
        "        self.v_fc2_bias = np.zeros_like(self.fc2_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.z1 = np.dot(x, self.fc1_weights) + self.fc1_bias\n",
        "        self.a1 = relu(self.z1)\n",
        "        self.z2 = np.dot(self.a1, self.fc2_weights) + self.fc2_bias\n",
        "        return self.z2\n",
        "\n",
        "    def backward(self, x, y, output, lr, momentum):\n",
        "        m = y.shape[0]\n",
        "        dz2 = output - y\n",
        "        dw2 = np.dot(self.a1.T, dz2) / m\n",
        "        db2 = np.sum(dz2, axis=0) / m\n",
        "        dz1 = np.dot(dz2, self.fc2_weights.T) * relu_derivative(self.z1)\n",
        "        dw1 = np.dot(x.T, dz1) / m\n",
        "        db1 = np.sum(dz1, axis=0) / m\n",
        "\n",
        "        self.v_fc2_weights = momentum * self.v_fc2_weights - lr * dw2\n",
        "        self.v_fc2_bias = momentum * self.v_fc2_bias - lr * db2\n",
        "        self.v_fc1_weights = momentum * self.v_fc1_weights - lr * dw1\n",
        "        self.v_fc1_bias = momentum * self.v_fc1_bias - lr * db1\n",
        "\n",
        "        self.fc2_weights += momentum * self.v_fc2_weights - lr * dw2\n",
        "        self.fc2_bias += momentum * self.v_fc2_bias - lr * db2\n",
        "        self.fc1_weights += momentum * self.v_fc1_weights - lr * dw1\n",
        "        self.fc1_bias += momentum * self.v_fc1_bias - lr * db1\n",
        "\n",
        "    def compute_loss(self, y_pred, y_true):\n",
        "        return np.mean(np.square(y_pred - y_true))"
      ],
      "metadata": {
        "id": "FQMDeTeu0byL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Neural Network\n",
        "input_size, hidden_size, output_size = 784, 500, 10\n",
        "lr, momentum, epochs, batch_size = 0.01, 0.9, 5, 64\n",
        "model = NeuralNet(input_size, hidden_size, output_size)\n"
      ],
      "metadata": {
        "id": "0zvqRnkV0eGc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy training data\n",
        "X_train = np.random.randn(batch_size, input_size)\n",
        "y_train = np.random.randint(0, output_size, (batch_size, output_size))\n"
      ],
      "metadata": {
        "id": "_CyGoCXA19hS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    outputs = model.forward(X_train)\n",
        "    loss = model.compute_loss(outputs, y_train)\n",
        "    model.backward(X_train, y_train, outputs, lr, momentum)\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZipx0ya1-6_",
        "outputId": "028fb8c8-e426-433c-cd5d-e13bb29c2df8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 30.5899\n",
            "Epoch [2/5], Loss: 118.2330\n",
            "Epoch [3/5], Loss: 70.1710\n",
            "Epoch [4/5], Loss: 32.1415\n",
            "Epoch [5/5], Loss: 27.9757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO-3UHYu2Aa-",
        "outputId": "8fb78c4c-1629-4fdd-de45-b4eddc998964"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n"
          ]
        }
      ]
    }
  ]
}